# CUDA-Linear-Algebra
CUDA implementation of vector addition and matrix multiplication to harness the power of parallel computing on GPUs 


> **Goal: Harness the power of GPUs with CUDA!**
---

## ðŸ“Œ Overview

This project demonstrates the use of **CUDA** to offload heavy computations to the **GPU**, enabling significant performance improvements over traditional CPU implementations.

### ðŸ”¹ Implemented Features
- **Vector Addition** â†’ Each element of two vectors is added **in parallel** on the GPU.
- **Matrix Multiplication** â†’ Each GPU thread computes **one element** of the resulting matrix.

---

## âš¡ Why CUDA?
- Massive Parallelism â†’ Thousands of threads execute simultaneously.
- Accelerated Execution â†’ Ideal for large vectors and matrices.
- Practical relevance â†’ Foundations of deep learning, simulations, and scientific computing.


