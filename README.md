# CUDA-Linear-Algebra
CUDA implementation of vector addition and matrix multiplication to harness the power of parallel computing on GPUs


This project demonstrates the use of CUDA to accelerate computations on GPUs.
It contains two main implementations:

- Vector addition: each element is added in parallel on the GPU.
- Matrix multiplication: each thread calculates one element of the resulting matrix.

âš¡ Computations are performed directly on the GPU to speed up execution compared to a sequential CPU version.

ðŸ“Š Results

- Performance gains on large vector and matrix sizes.

- Concrete illustration of parallel programming with CUDA.
